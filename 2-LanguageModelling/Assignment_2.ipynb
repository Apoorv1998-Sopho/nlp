{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1, 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\apoor\\Miniconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\utils\\__init__.py:4: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\apoor\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#imports\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import islice\n",
    "\n",
    "# custom functions\n",
    "from helper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"../books/adventures_sherlock_holmes.txt\"\n",
    "sentences = getSents(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lower case words, and remove punctuations.\n",
    "normalizedSentences = lowerPunct(sentences)\n",
    "\n",
    "# add Start stop symbols\n",
    "finalSentences = addStartStop(normalizedSentences)\n",
    "\n",
    "# divide the corpus into test and train\n",
    "train, test = train_test_split(finalSentences,\\\n",
    "                               test_size=0.2,\\\n",
    "                               random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding the MLEs for all the ngrams\n",
    "N = 4\n",
    "mles = []\n",
    "nGrams = [None]\n",
    "for i in range(1, N + 1):\n",
    "    nGrams.append(nGramCount(train, i))\n",
    "    \n",
    "for i in range(1, N + 1):\n",
    "    mles.append(MLE(nGrams[i], nGrams[i-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<s> but the': 0.08823529411764706,\n",
       " 'but the deception': 0.023809523809523808,\n",
       " 'the deception could': 1.0,\n",
       " 'deception could not': 1.0,\n",
       " 'could not be': 0.1346153846153846,\n",
       " 'not be kept': 0.043478260869565216,\n",
       " 'be kept up': 0.5,\n",
       " 'kept up forever': 1.0,\n",
       " 'up forever </s>': 1.0,\n",
       " '<s> oh sir': 0.05555555555555555,\n",
       " 'oh sir do': 0.3333333333333333,\n",
       " 'sir do you': 1.0,\n",
       " 'do you not': 0.12,\n",
       " 'you not think': 0.14285714285714285,\n",
       " 'not think that': 0.4117647058823529}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change the value of ngram to get it's MLE\n",
    "ngram = 3\n",
    "dict(islice(mles[ngram-1].items(), 0, 15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Possible number of ngrams possible\n",
    "poss_avai=[]\n",
    "for i in range(1, N+1):\n",
    "    poss_avai.append(possible_avail(nGrams[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unigrams\n",
      "possible: 23698170\n",
      "present: 6885\n",
      "\n",
      "bigrams\n",
      "possible: 823916121\n",
      "present: 40594\n",
      "\n",
      "trigrams\n",
      "possible: 2301980878\n",
      "present: 67853\n",
      "\n",
      "quadgrams\n",
      "possible: 2700573778\n",
      "present: 73493\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# first val contains the possible no of ith ngrams\n",
    "# second val is the number of unique ith ngrams\n",
    "# where i > 1\n",
    "s = [\"unigrams\", \"bigrams\", \"trigrams\", \"quadgrams\"]\n",
    "for so in range(len(s)):\n",
    "    print (s[so])\n",
    "    print (\"possible:\", poss_avai[so][0])\n",
    "    print (\"present:\", str(poss_avai[so][1]) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4\n",
    "### part a (Sentence Generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence generated from 4 gram model:\n",
      "two thousand five hundred pounds was the amount but i can not imagine\n",
      "sentence generated from 3 gram model:\n",
      "surely it would all have been shamefully used\n",
      "sentence generated from 2 gram model:\n",
      "would see one as morning at was so sorely and duke his case\n",
      "sentence generated from 1 gram model:\n",
      "apparition crates it flowing anxiety and been dusk you across in balustraded face absolute remarkable\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Sentence Generator:\n",
    "No smoothing used till here.\n",
    "'''\n",
    "k = 10 # atleast k big sentences, if possible\n",
    "for i in range(N, 0, -1):\n",
    "    print ('sentence generated from' , i, 'gram model:') \n",
    "    print(Generator(mles[i-1], k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### part b (Sentence Probability in log-spc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-18.4677342168191"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PrLog(\"all or and duke say so he rushed under it accompli\", mles[1]) # only for 2gram model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5 (Add1Smoothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Add 1 Smoothing for bigrams returns\n",
    "returns a dictionary with increased\n",
    "counts for every possible bigram\n",
    "'''\n",
    "AD = Add1Smooth(nGrams[2], nGrams[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New count 'This is': 9.490566478853482\n",
      "Old count 'This is': 29\n",
      "New count 'you are': 18.664780741745183\n",
      "Old count 'you are': 58\n",
      "New count 'leave your': 1.265408863847131\n",
      "Old count 'leave your': 3\n"
     ]
    }
   ],
   "source": [
    "print (\"New count 'This is':\", AD.NewCount(\"this is\"))\n",
    "print (\"Old count 'This is':\", nGrams[2][\"this is\"])\n",
    "print (\"New count 'you are':\", AD.NewCount(\"you are\"))\n",
    "print (\"Old count 'you are':\", nGrams[2][\"you are\"])\n",
    "print (\"New count 'leave your':\", AD.NewCount(\"leave your\"))\n",
    "print (\"Old count 'leave your':\", nGrams[2][\"leave your\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add One smoothing casuses drastic changes as can be seen above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 6 (GoodTuring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Good Turing reduced counts for bigrams\n",
    "GT = GoodTuring(nGrams[2], nGrams[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only size-1 arrays can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-1c651af24bfe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# finding the new counts of 10 bigrams with length i\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mgtn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNewCounts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcounts\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'prev count vs goodTuring count*'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mgtn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Cheenu\\Github\\nlp\\2-LanguageModelling\\helper.py\u001b[0m in \u001b[0;36mNewCounts\u001b[1;34m(self, counts)\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# f(x) = a*exp(-kx) == Nc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 315\u001b[1;33m         \u001b[0mpopt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcurve_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFreqN\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFreqN\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    316\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0munCalculated\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m             \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\apoor\\Miniconda3\\envs\\nlp\\lib\\site-packages\\scipy\\optimize\\minpack.py\u001b[0m in \u001b[0;36mcurve_fit\u001b[1;34m(f, xdata, ydata, p0, sigma, absolute_sigma, check_finite, bounds, method, jac, **kwargs)\u001b[0m\n\u001b[0;32m    749\u001b[0m         \u001b[1;31m# Remove full_output from kwargs, otherwise we're passing it in twice.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    750\u001b[0m         \u001b[0mreturn_full\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'full_output'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 751\u001b[1;33m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mleastsq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDfun\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mjac\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfull_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    752\u001b[0m         \u001b[0mpopt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpcov\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfodict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m         \u001b[0mcost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minfodict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'fvec'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\apoor\\Miniconda3\\envs\\nlp\\lib\\site-packages\\scipy\\optimize\\minpack.py\u001b[0m in \u001b[0;36mleastsq\u001b[1;34m(func, x0, args, Dfun, full_output, col_deriv, ftol, xtol, gtol, maxfev, epsfcn, factor, diag)\u001b[0m\n\u001b[0;32m    381\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m         \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 383\u001b[1;33m     \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'leastsq'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'func'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    384\u001b[0m     \u001b[0mm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    385\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\apoor\\Miniconda3\\envs\\nlp\\lib\\site-packages\\scipy\\optimize\\minpack.py\u001b[0m in \u001b[0;36m_check_func\u001b[1;34m(checker, argname, thefunc, x0, args, numinputs, output_shape)\u001b[0m\n\u001b[0;32m     25\u001b[0m def _check_func(checker, argname, thefunc, x0, args, numinputs,\n\u001b[0;32m     26\u001b[0m                 output_shape=None):\n\u001b[1;32m---> 27\u001b[1;33m     \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0matleast_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthefunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx0\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mnuminputs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0moutput_shape\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0moutput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0moutput_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\apoor\\Miniconda3\\envs\\nlp\\lib\\site-packages\\scipy\\optimize\\minpack.py\u001b[0m in \u001b[0;36mfunc_wrapped\u001b[1;34m(params)\u001b[0m\n\u001b[0;32m    461\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtransform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    462\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mfunc_wrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 463\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mydata\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    464\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    465\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mfunc_wrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Cheenu\\Github\\nlp\\2-LanguageModelling\\helper.py\u001b[0m in \u001b[0;36mfunc\u001b[1;34m(x, a, k)\u001b[0m\n\u001b[0;32m    312\u001b[0m         \u001b[1;31m# estimate uncalculated\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# f(x) = a*exp(-kx) == Nc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 314\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    315\u001b[0m         \u001b[0mpopt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcurve_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFreqN\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFreqN\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0munCalculated\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "# finding the new counts of 10 bigrams with length i\n",
    "gtn = GT.NewCounts(counts=10)\n",
    "print ('prev count vs goodTuring count*')\n",
    "gtn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plotting discount\n",
    "x = [keys for keys in gtn.keys()]\n",
    "y = [keys - gtn[keys] for keys in gtn.keys()]\n",
    "plt.scatter(x, y)\n",
    "plt.xlabel(\"Initial_counts\")\n",
    "_ = plt.ylabel(\"Difference in counts (Old - New)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the above graph, the discounts are nearly same with an average value around, `0.957`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (sum(y[1:])/9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GT.Prob(\"all or\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
