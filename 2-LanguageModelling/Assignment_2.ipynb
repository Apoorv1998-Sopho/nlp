{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1, 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\apoor\\Miniconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\utils\\__init__.py:4: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\apoor\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#imports\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import islice\n",
    "\n",
    "# custom functions\n",
    "from helper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"../books/adventures_sherlock_holmes.txt\"\n",
    "sentences = getSents(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lower case words, and remove punctuations.\n",
    "normalizedSentences = lowerPunct(sentences)\n",
    "\n",
    "# add Start stop symbols\n",
    "finalSentences = addStartStop(normalizedSentences)\n",
    "\n",
    "# divide the corpus into test and train\n",
    "train, test = train_test_split(finalSentences,\\\n",
    "                               test_size=0.2,\\\n",
    "                               random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding the MLEs for all the ngrams\n",
    "N = 4\n",
    "mles = []\n",
    "nGrams = [None]\n",
    "for i in range(1, N + 1):\n",
    "    nGrams.append(nGramCount(train, i))\n",
    "    \n",
    "for i in range(1, N + 1):\n",
    "    mles.append(MLE(nGrams[i], nGrams[i-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<s> but the': 0.08823529411764706,\n",
       " 'but the deception': 0.023809523809523808,\n",
       " 'the deception could': 1.0,\n",
       " 'deception could not': 1.0,\n",
       " 'could not be': 0.1346153846153846,\n",
       " 'not be kept': 0.043478260869565216,\n",
       " 'be kept up': 0.5,\n",
       " 'kept up forever': 1.0,\n",
       " 'up forever </s>': 1.0,\n",
       " '<s> oh sir': 0.05555555555555555,\n",
       " 'oh sir do': 0.3333333333333333,\n",
       " 'sir do you': 1.0,\n",
       " 'do you not': 0.12,\n",
       " 'you not think': 0.14285714285714285,\n",
       " 'not think that': 0.4117647058823529}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change the value of ngram to get it's MLE\n",
    "ngram = 3\n",
    "dict(islice(mles[ngram-1].items(), 0, 15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Possible number of ngrams possible\n",
    "poss_avai=[]\n",
    "for i in range(1, N+1):\n",
    "    poss_avai.append(possible_avail(nGrams[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unigrams\n",
      "possible: 23698170\n",
      "present: 6885\n",
      "\n",
      "bigrams\n",
      "possible: 823916121\n",
      "present: 40594\n",
      "\n",
      "trigrams\n",
      "possible: 2301980878\n",
      "present: 67853\n",
      "\n",
      "quadgrams\n",
      "possible: 2700573778\n",
      "present: 73493\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# first val contains the possible no of ith ngrams\n",
    "# second val is the number of unique ith ngrams\n",
    "# where i > 1\n",
    "s = [\"unigrams\", \"bigrams\", \"trigrams\", \"quadgrams\"]\n",
    "for so in range(len(s)):\n",
    "    print (s[so])\n",
    "    print (\"possible:\", poss_avai[so][0])\n",
    "    print (\"present:\", str(poss_avai[so][1]) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4\n",
    "### part a (Sentence Generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "and no more words were needed\n",
      "anything else for me to you said holmes laughing as he come to me in a treat\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Sentence Generator:\n",
    "No smoothing used till here.\n",
    "'''\n",
    "k = 10 # atleast k big sentences, if possible\n",
    "for i in range(N, 0, -1):\n",
    "    print (Generator(mles[i-1], k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### part b (Sentence Probability in log-spc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PrLog(\"well he and in the wall the and in of told and behind him\", mles[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5 (Add1Smoothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Add 1 Smoothing for bigrams returns\n",
    "returns a dictionary with increased\n",
    "counts for every possible bigram\n",
    "'''\n",
    "AD = Add1Smooth(nGrams[2], nGrams[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"New count 'This is':\", AD.NewCount(\"this is\"))\n",
    "print (\"Old count 'This is':\", nGrams[2][\"this is\"])\n",
    "print (\"New count 'you are':\", AD.NewCount(\"you are\"))\n",
    "print (\"Old count 'you are':\", nGrams[2][\"you are\"])\n",
    "print (\"New count 'leave your':\", AD.NewCount(\"leave your\"))\n",
    "print (\"Old count 'leave your':\", nGrams[2][\"leave your\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add One smoothing casuses drastic changes as can be seen above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 6 (GoodTuring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Good Turing reduced counts for bigrams\n",
    "GT = GoodTuring(nGrams[2], nGrams[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# finding the new counts of 10 bigrams with length i\n",
    "gtn = GT.NewCounts(counts=10)\n",
    "print ('prev count vs goodTuring count*')\n",
    "gtn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plotting discount\n",
    "x = [keys for keys in gtn.keys()]\n",
    "y = [keys - gtn[keys] for keys in gtn.keys()]\n",
    "plt.scatter(x, y)\n",
    "plt.xlabel(\"Initial_counts\")\n",
    "_ = plt.ylabel(\"Difference in counts (Old - New)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the above graph, the discounts are nearly same with an average value around, `0.957`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (sum(y[1:])/9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtAll = GT.NewCounts(counts=55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtAll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
